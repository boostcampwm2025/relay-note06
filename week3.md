## `week2.md`의 퀘스트에 대하여 토론하기

> "전달받은 노트와 퀘스트를 비판적으로 바라보고, 개선점을 논의합니다."

**퀘스트 1. 헷갈리는 개념 중심 AI 퀴즈 생성하기<br>
퀘스트 2. 자신이 아는 부분에 대해서 AI에게 주관식 퀴즈 받기**

잘 알지 못하거나 헷갈리는 개념은 퀘스트 1을 통해 학습이 가능하며,<br>
확실하게 아는 개념 같은 경우에는 퀘스트 2를 통해 학습이 가능합니다.<br>

퀘스트 1은 생성하고 해결한 문제를 Quiz.md에 업로드하여 기록을 축적할 수 있는 특징이 있고,<br>
퀘스트 2는 각자의 학습정리.md에 내용을 기록함으로써 복습이 가능하다는 특징이 있습니다.<br>

두 퀘스트 모두 프로젝트의 목적인 “LLM을 활용한 학습 퀴즈 생성”에 충분히 부합하고,<br>
모르는 개념과 아는 개념을 각각의 퀘스트를 통해 모두 학습할 수 있다보니,<br>
서로 상호 보완이 가능하기에 이대로 퀘스트 형식을 유지해도 좋다고 판단했습니다.<br>

**퀘스트 3. 페르소나 기반 프롬프트 vs 일반 프롬프트 - 생성된 문제의 질 비교**

LLM을 사용할 때 페르소나를 부여하는 것이 결과의 창의성, 전문성, 일관성 등에 영향을 준다는 주장을 확인하고,<br>
이러한 영향을 활용하여 LLM을 십분 활용하는 목적의 퀘스트입니다.<br>

동시에 내가 학습한 내용을 토대로 문제를 생성하며 학습하기 때문에 복습 효과도 얻을 수 있어<br>
LLM 활용도 향상을 꾀하며 학습 효과도 부가적으로 가져갈 수 있는 장점이 있는 퀘스트라 이해했습니다.<br>

문제의 수나 난이도와 같은 변수나 기준점을 활용하여 LLM이 생성하는 결과를 확인하고<br>
비교하는 과정을 통해 LLM의 답변을 사용자가 원하는 수준에 맞춰 생성할 수 있는 장점이 있습니다.<br>

이 퀘스트 또한 프로젝트 목적인 “LLM을 활용한 학습 퀴즈 생성”에 충분히 부합하며<br>
동시에 LLM을 잘 쓰는 방법을 알 수 있어 충분히 유익하다고 느껴 퀘스트 형식을 유지해도 좋다고 판단했습니다.<br>

퀘스트 4. **설계 검토, AI에게 한 번 물어보기**

설계에 대한 검증을 AI에게 보완을 부탁하는 것이 아닌,<br>
별점과 한 줄 평을 통해 부족한 부분에 대한 인식을 통해 스스로 설계를 보완하도록 유도하는 퀘스트입니다.<br>

본 릴레이 프로젝트의 방향성과도 알맞고, 의도도 좋습니다.<br>
다만, 한 줄 평으로는 개선 방향을 설정하는 데에 헤맬 수 있으므로<br>
이를 보완하기 위해 내가 설계한 내용을 AI를 활용하여 흐름도로 그린 후 직관적으로 검토해 보는 것도 좋은 방법이라고 생각했습니다.<br>

## `week3.md`에 남길 퀘스트 아이디어 탐색하기

> "조사 및 실현 가능한 퀘스트 아이디어를 탐색합니다."

여기에 내용 입력하기...

# Week3 퀘스트

## 퀘스트 1. 



## 퀘스트 2.



## 퀘스트 3.



## 퀘스트 4.

