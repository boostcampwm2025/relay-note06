## AI를 그동안 어떻게 사용해왔는지 이야기해보기

`K022_장무호`
- 처음에는 AI에게 질문을 하거나, 직접 코드를 작성하도록 하는 방식으로 자주 사용해왔다.
- 이후에는 자기 주도적인 학습 방법을 적용, 유지하기 위해 코드를 직접 작성하지 않고 현재 코드의 문제와 개선 방안, 작성해야 하는 코드의 동작을 최소 단위로 나누고 말로 풀어 설명하도록 했다.

`J060_김윤영`
- 설계를 할 때 사용하거나, 현재 코드의 동작이나 가독성을 개선하기 위해 피드백을 받는 형태로도 사용했다.

`J014_강지호`
- 초기에는 AI에게 코드 생성을 요구했으나, 이후 생각하는 기회를 놓치 않고자 최대한 내가 직접 생각할 수 있는 방향의 프롬프트를 사용했다.
- 현재 자신의 목적을 설명하고, 그 목적과 어울리는 방향의 답변을 생성하게 유도했다.

---

## `week2.md`의 퀘스트에 대하여 토론하기

> "전달받은 노트와 퀘스트를 비판적으로 바라보고, 개선점을 논의합니다."

### 퀘스트 1. 헷갈리는 개념 중심 AI 퀴즈 생성하기<br>퀘스트 2. 자신이 아는 부분에 대해서 AI에게 주관식 퀴즈 받기

잘 알지 못하거나 헷갈리는 개념은 퀘스트 1을 통해 학습이 가능하며,<br>
확실하게 아는 개념 같은 경우에는 퀘스트 2를 통해 학습이 가능합니다.<br>

퀘스트 1은 생성하고 해결한 문제를 Quiz.md에 업로드하여 기록을 축적할 수 있는 특징이 있고,<br>
퀘스트 2는 각자의 학습정리.md에 내용을 기록함으로써 복습이 가능하다는 특징이 있습니다.<br>

두 퀘스트 모두 프로젝트의 목적인 “LLM을 활용한 학습 퀴즈 생성”에 충분히 부합하고,<br>
모르는 개념과 아는 개념을 각각의 퀘스트를 통해 모두 학습할 수 있다보니,<br>
서로 상호 보완이 가능하기에 이대로 퀘스트 형식을 유지해도 좋다고 판단했습니다.<br>

### 퀘스트 3. 페르소나 기반 프롬프트 vs 일반 프롬프트 - 생성된 문제의 질 비교

LLM을 사용할 때 페르소나를 부여하는 것이 결과의 창의성, 전문성, 일관성 등에 영향을 준다는 주장을 확인하고,<br>
이러한 영향을 활용하여 LLM을 십분 활용하는 목적의 퀘스트입니다.<br>

동시에 내가 학습한 내용을 토대로 문제를 생성하며 학습하기 때문에 복습 효과도 얻을 수 있어<br>
LLM 활용도 향상을 꾀하며 학습 효과도 부가적으로 가져갈 수 있는 장점이 있는 퀘스트라 이해했습니다.<br>

문제의 수나 난이도와 같은 변수나 기준점을 활용하여 LLM이 생성하는 결과를 확인하고<br>
비교하는 과정을 통해 LLM의 답변을 사용자가 원하는 수준에 맞춰 생성할 수 있는 장점이 있습니다.<br>

이 퀘스트 또한 프로젝트 목적인 “LLM을 활용한 학습 퀴즈 생성”에 충분히 부합하며<br>
동시에 LLM을 잘 쓰는 방법을 알 수 있어 충분히 유익하다고 느껴 퀘스트 형식을 유지해도 좋다고 판단했습니다.<br>

### 퀘스트 4. 설계 검토, AI에게 한 번 물어보기

설계에 대한 검증을 AI에게 보완을 부탁하는 것이 아닌,<br>
별점과 한 줄 평을 통해 부족한 부분에 대한 인식을 통해 스스로 설계를 보완하도록 유도하는 퀘스트입니다.<br>

본 릴레이 프로젝트의 방향성과도 알맞고, 의도도 좋습니다.<br>
다만, 한 줄 평으로는 개선 방향을 설정하는 데에 헤맬 수 있으므로<br>
이를 보완하기 위해 내가 설계한 내용을 AI를 활용하여 흐름도로 그린 후 직관적으로 검토해 보는 것도 좋은 방법이라고 생각했습니다.<br>

---

## `week3.md`에 남길 퀘스트 아이디어 탐색하기

> "조사 및 실현 가능한 퀘스트 아이디어를 탐색합니다."

1. 기본 퀴즈 생성기 아이디어
- 배경 및 목적 : 기본적인 개념을 부담 없이 가볍게 확인할 수 있는 문제를 작성합니다.
- 수행 방법 : OX 또는 객관식 문제를 생성하고, 해결합니다. 문제와 해결 과정을 학습정리나 Slack 등, 자신이 원하는 문서나 위치에 기록합니다.
2. AI와 피어 세션 퀴즈 관련 주제 조사
- 배경 및 목적: AI를 활용한 퀴즈에 대한 다양한 접근을 조사하고, 이를 퀘스트에 어떻게 적용시킬 지 생각해 봅니다.
- 수행 내용
  - 대부분 단순한 퀴즈 생성 및 답변 형태로 진행하였는데, 이 중 인상적인 항목은 다음과 같습니다.
  - 각 질문에 레벨과 점수를 매기고, 연속해서 정답을 제출하면 추가 점수를 얻는 등의 게임 형식으로 진행하는 퀴즈
  - AI의 설명에 의도적으로 거짓말을 섞게 하여 찾고 반박하는 퀴즈
적용: 인상적이었던 퀴즈 관련을 AI 피어 세션 링크를 남겨 이를 참고해 원하는 형식으로 퀴즈를 생성하고 참여할 수 있도록 선택지를 제공합니다.
3. [AI를 활용한 TIME + ChatGPT 기반 뉴스 아카이브 퀴즈 생성 사례](https://time.com/6284776/time-chatgpt-news-quiz/?utm_source=chatgpt.com)<br>
- Time 기사에서 발췌한 내용들을 토대로, 뻔하지 않으면서도 흥미로운 주제의 퀴즈와 네 가지 선택지(정답 하나와 그럴듯하지만 틀린 세 가지 답변)을 생성한 사례가 있습니다.
- 그와 더불어 원래 텍스트를 바탕으로 올바른 답변에 대한 정보적 맥락을 제공하도록 하였습니다.
4. [ChatGPT의 GPT‑4 기반 ‘Study Mode’ 기능 (OpenAI / The Verge 등)](https://www.tomsguide.com/ai/i-put-chatgpt-study-mode-to-the-test-with-7-prompts-heres-my-grade?utm_source=chatgpt.com)<br>
- 개념 분석 테스트 / 플래시카드 테스트 / 사용자 정의 자료 업로드 테스트 / 연습문제 테스트 / 틀렸던 문제 테스트 등의 방식을 활용한 학습 사례를 소개합니다.

---

# Week3 퀘스트

## 퀘스트 제작하기

> "너무 열정적으로 퀘스트를 만들다 보니 6가지가 되어버렸습니다... 원하는 퀘스트만을 골라 수행해주시면 좋을 것이라 생각합니다."

**퀘스트0 : 원하는 퀘스트를 만들어 수행하기**

**배경**

- 언젠가 퀘스트를 사용자가 직접 하나씩 만들어보는 것도 괜찮을 것 같다고 생각했는데, 이번에 시도해보면 어떨까 하는 생각을 해서 제작함.

**목적**

- 미션을 수행하는 사람들이 <b>"학습 및 현재 프로젝트의 의도와 관련된 퀘스트"</b>를 자유롭게 구성하여 수행할 수 있도록 자유도를 부여하고자 함.
- AI와 피어세션의 연장선으로 다양한 방식으로 활용해 본다.

**수행 방법**

1. 다음 AI와 피어 세션 퀘스트 형식을 참고하여 자유로운 형식으로 생성한다. (읽고 나서 좋아요 한 번씩 눌러 주세요! 본인 아닙니다.)
- [게임 형식으로 진행하는 AI 퀴즈쇼](https://lucas.codesquad.kr/boostcamp-2025/digest/u/aea4cbd3cd82effb2841c8a09152608f:682d83f2b0633a9ab2b7abe20fc7b8a4)
- [날 속이려는 AI에게 반박하기](https://lucas.codesquad.kr/boostcamp-2025/digest/u/1397be56b6c9f3994cb953e3c00c96ce:6a94897ba7d6ef7548c018d3b65bd21b)

**퀘스트1 : 헷갈리는 개념 중심 AI 퀴즈 생성하기**

**배경**

- 학습을 마친 후에도 개념이 애매하거나 헷갈리는 경우가 많음.
- 이러한 부분을 정리하고 AI를 통해 퀴즈를 만들어 학습 정확도를 높이고자 함.

**목적**

- 학습 내용을 메타인지 관점에서 점검하고 취약한 부분을 식별한다.
- AI를 활용해 스스로 퀴즈를 생성하고 반복 학습할 수 있도록 한다.
- 학습의 깊이를 확인하고 지속 가능한 복습 시스템을 만든다.
- 학습 내용을 메타인지 관점에서 점검하고 취약한 부분을 식별한다.
- AI를 활용해 스스로 퀴즈를 생성하고 반복 학습할 수 있도록 한다.
- 학습의 깊이를 확인하고 지속 가능한 복습 시스템을 만든다.

**수행 방법**

1. 자신이 작성한 `학습정리.md`를 보면서 스스로 헷갈리는 개념을 따로 정리한다.
2. 정리한 내용을 GPT를 통해 3개 이상의 퀴즈를 생성한다.
3. 생성한 퀴즈와 해결 과정을 [quiz.md](https://github.com/boostcampwm2025/relay-note06/blob/main/quiz.md)나 각자의 `학습정리.md`와 같은, 원하는 형식으로 정리한다.
4. 학습을 점검한다.

**퀘스트 2. 자신이 아는 부분에 대해서 AI에게 주관식 퀴즈 받기**

**배경**

- 부스트캠프 학습 철학 중 학습한 내용을 자신만의 것으로 만들기 위해 자신의 글로 정리하는 것을 느꼈다. 그래서 AI가 퀴즈로 제공해준 주제에 대해 자신이 학습한 내용을 주관식으로 작성하며 정리하면 좋을 것 같다.
- 자신이 안다고 생각하는 것에 대해 누군가가 물어보면 잘 대답하지 못하는 경우가 있는데 해당 퀘스트를 통해 기술 면접을 준비하거나 자신이 아는 것을 다른 사람에게 더 잘 설명할 수 있는 능력을 기를 수 있을 것 같다.

**목적**

- 자신이 안다고 생각하는 것에서 부족한 것이 무엇인지 파악하기 위함
- 자신이 학습한 내용을 자신만의 것으로 정리하기 위함
- 자신이 알고 있는 지식을 설명할 수 있는 능력을 기르기 위함

**수행 방법**

1. `학습정리.md`를 작성한 뒤, 자신이 충분히 이해했다고 생각하는 개념을 선정한다.
2. 해당 개념에 대해 GPT에게 3개 이상의 주관식 퀴즈 생성을 요청한다.
3. 생성된 문제에 대해 학습 자료를 보지 않고 스스로 답변을 작성한다.
4. 이후 학습정리.md나 추가 학습을 통해 부족했던 부분을 보완하고, 개선된 답변을 작성한다.
5. 질문, 문제, 1차 답변, 보완한 2차 답변을 포함해 [quiz.md](http://quiz.mdhttps://github.com/boostcampwm2025/relay-note06/blob/main/quiz.md)나 각자의 `학습정리.md`와 같은, 원하는 장소에 정리한다.

**퀘스트 3. 페르소나 기반 프롬프트 vs 일반 프롬프트 - 생성된 문제의 질 비교**

**배경**

- AI에 페르소나를 부여하는 것이 결과의 창의성, 전문성, 일관성 등에 영향을 준다는 주장은 다양한 분야에서 제기되고 있다. 따라서 이를 검증하고자 학습한 내용을 바탕으로 프롬프트 결과를 비교해보면서 학습내용 점검도 하면서 실제로 페르소나가 생성된 결과의 영향을 주는지 시험하기위해 퀘스트를 제작해봤다.

**목적**

- 학습한 내용을 바탕으로 AI가 생성한 문제를 통해 복습 및 자기 점검
- 페르소나 유무에 따른 프롬프트 설계 차이가 문제의 적절성에 어떤 영향을 주는지 분석

**수행 방법**

1. 학습정리.md를 작성하고 해당 내용을 바탕으로 문제의 수, 난이도를 정한다
2. AI에게 그냥 문제를 생성해달라고 했을 때와 페르소나(소프트웨어 전문가, 선생님 등)을 적용했을 때의 문제를 비교한다.
3. 페르소나에 따른 생성된 문제, 프롬프트, 사용자가 제시한 프롬프트에 대한 AI의 답변, 느낀 점 등을 자유롭게 정리한다.

**퀘스트 4.설계 검토, AI에게 물어보기**

**배경**

매일 미션을 수행하면서 설계 → 구현의 흐름을 반복하지만, 설계의 타당성을 점검할 기회는 부족합니다. AI를 활용해 설계안을 피드백하며 완성도 높은 설계안을 만들고, 그 내용을 토대로 추가적으로 흐름도를 생성하여 설계력 향상과 구현의 편리함을 유도할 수 있다.

**목적**

- 설계안을 AI에게 설명하고, 객관적인 평가를 받아본다.
- AI의 피드백을 설계의 강점과 개선점을 파악한다.
- 필요하다면 동료들과 설계 평가를 공유하여 서로의 접근 방식을 이해하고 배운다.

**수행 방법**

1. 매일 미션 설계 초안을 완성한 뒤, AI에게 설명한다. (텍스트로 5줄 이상 권장)
2. AI에게 다음 사항을 요청한다.
- 현재 설계에서 부족한 점이 무엇이며, 어떻게 더 보완할 수 있는지 아이디어를 제시해 줘
- (흐름도가 필요하다면)만약 이 설계안을 통해 구현을 하는 것이 좋아보인다면, 설계안을 흐름도로 표현해 줘
1. 설계안과 (흐름도를 생성하였을 경우) 흐름도를 `README.md`와 같은, 원하는 장소에 정리한다.

**퀘스트 5. 기본 퀴즈 생성기 아이디어**

**배경**

- 아침과 같은 조금은 졸릴 수 있는 시간이나, 자투리 시간을 어떻게 하면 학습과 관련하여 활용할 수 있을지 고민함.

**목적**

- 짧은 시간을 십분 활용하여 가벼운 문제를 풀면서 개념을 리마인드하기 위함.

**수행 방법**

1. 어떠한 주제에 관련된 기본이 되는 개념을 토대로 OX 또는 객관식 문제를 생성하고 문제를 해결한다.
2. 문제와 해결 과정을 [quiz.md](https://github.com/boostcampwm2025/relay-note06/blob/main/quiz.md)나 `학습정리.md`, 또는 Slack 등 자신이 원하는 문서나 위치에 정리한다.

---

# 퀘스트 수행 결과

### J066_김재훈 - 퀘스트0 : 원하는 퀘스트를 만들어 수행하기
#### 선정이유 
다른 퀘스트들은 이미 전에 AI를 사용해보면서 대부분 해본 것들이라서 나만의 한번도 안해본 퀘스트 만들어서 수행 해보고 싶었다.

#### 수행결과

<details>
  
<summary><strong>08.07</strong></summary>

> 내가 만든 퀘스트: AI피어세션에서 조금 부족하게 했던 퀴즈 RPG로 재밌게 학습해보기
> 의도: 퀴즈 RPG로 게임하듯이 재밌게 학습해보자

## 진행 사진

<img width="732" height="1123" alt="스크린샷 2025-08-08 113301" src="https://github.com/user-attachments/assets/dc64c07b-b0c4-4316-92f8-6b72e7b08f1a" />
<img width="877" height="606" alt="스크린샷 2025-08-08 113436" src="https://github.com/user-attachments/assets/bae25485-d104-4ab1-8ec5-e8e14572b338" />
<img width="872" height="634" alt="스크린샷 2025-08-08 113440" src="https://github.com/user-attachments/assets/fedc07e0-9df7-4460-9e7d-a86c63b1e501" />
<img width="888" height="768" alt="스크린샷 2025-08-08 113449" src="https://github.com/user-attachments/assets/889271ff-c9a4-40ba-bf35-1631580aad70" />


## 느낀점

그냥 퀴즈를 받아서 하기보다는 RPG게임으로 퀴즈를 바탕으로 성장하는 기분도 느끼면서 조금 지루하거나 의욕이 부족할 떄 재밌게 학습할 수 있어서 효과가 생각보다 좋았던 것 같다.
오답이 나왔을 때 조금 더 지식을 정리를 잘 해주게끔 또, 게임 룰을 조금 더 구체화해서 프롬프트를 잘 작성해서 실행하면 정말 게임같은 재밌는 학습이 가능할 것 같다.

</details>

### J079_김한경 - 퀘스트 3. 페르소나 기반 프롬프트 vs 일반 프롬프트 - 생성된 문제의 질 비교
#### 선정이유 
평소에 어떻게 하면 AI를 효과적으로 쓸 지에 대한 고민이 많았고 페르소나 기반으로 하면 질적으로 더 좋은 결과가 생성될 지 궁금했기 때문에 비교해보고 싶었다.

#### 수행결과

---

### J196_이승지 - 퀘스트 4.설계 검토, AI에게 물어보기
#### 선정이유 
설계는 이후 미션 진행의 방향성이 되기 때문에 중요하다.
잘못된 설계는 잘못된 방향으로 이어진다.
평소에도 AI에게 설계를 검토받곤 하지만, 이 릴프를 계기로 좀 더 정교하게 AI를 활용해서 검토를 받아봐야겠다.

#### 수행결과

<details>
  
<summary><strong>08.05</strong></summary>

## ✅ 전체 구조 피드백

### 👍 장점

- **모듈 책임을 나누려는 시도**가 명확해. (cli, main, vdb, utils, command)
- CLI 기반 인터페이스 흐름이 **명확하고 사용하기 쉬움**
- `storage/` 디렉토리로 **파일 저장 고려**도 포함된 점도 좋음

---

## 🔍 개선점 (실무 기준 비판적 피드백)

### 1. **모듈 책임 분리 – 일부 애매함**

| 모듈 | 개선 포인트 |
| --- | --- |
| `main.js` | DB 로직까지 일부 수행 (→ 너무 많은 책임) |
| `cli.js` | 단순 입력만 받는 건 OK, 그러나 사용자 유효성 검증은 어디서? `main`이 너무 과도하게 끌어안게 됨 |
| `vdb.js` | DB와 스토리지 책임을 동시에 가짐 (SRP 위반 가능성 있음) |
| `utils.js` | 기능 범위가 너무 광범위. embedding, distance, pooling은 다른 관심사 |

✅ **개선 제안:**

- `storage.js` 분리 → DB 내부 상태의 **저장/로드 전담**
- `embedding.js` 분리 → 모델 초기화, 임베딩 추출
- `distance.js` → 유사도, 거리 계산만 따로 분리
- `vdb.js`는 순수하게 **메모리상의 DB 추상화만** 하도록 제한

---

### 2. **입력 흐름 설계 – `cli.js`와 `main.js` 간 책임 재조정 필요**

현재:

- `cli`는 사용자 입력만 받고, 해석/실행은 전부 `main.js`

👉 이 경우 **main.js가 커지면서 유닛테스트가 어려워짐**

✅ 개선 제안:

- `cli.js`가 `Command` 객체 (명령어, args, input string 등)를 만들어 넘기고
- `main.js`는 해당 커맨드를 `command-handler.js` 같은 곳으로 위임

---

### 3. **명령어 정의 (`commands.js`) – 확장성 좋지만**

현재는 단순한 상수 저장소로 보임

✅ 개선 제안:

- `CommandEnum`, `CommandHelpMap`, `CommandPrompts` 등 **명령어에 대한 메타데이터를 통합적으로 관리**하는 구조가 필요
- (실무에서는 슬래시 커맨드처럼 autocompletion과 도움말 자동 생성까지 연결됨)

---

### 4. **빠진 기능 / 예외처리**

| 빠진 항목 | 설명 |
| --- | --- |
| ✔ 중복 데이터 체크 | `add()` 시 동일 id 체크 없음 |
| ✔ 예외 처리 | I/O, 모델 로딩, JSON 파싱, 없는 명령 등 전혀 없음 |
| ✔ CLI 종료 처리 | Ctrl+C 혹은 오류 발생 시 graceful shutdown |
| ✔ 유사도 정렬 | `search` 시 상위 N개 유사도 정렬 반환 로직은 명세에 없음 |
| ✔ 벡터 차원 미스매치 처리 | 임베딩 dim과 DB dim 불일치 체크 로직 필요 |
| ✔ 초기화 시 기존 파일 삭제 여부 선택 |  |

---

### 5. **파일 기반 스토리지 – 이대로는 위험**

- `vdb.js` 내에서 파일을 직접 읽고 쓰는 방식이라면, **동시성 문제, 락 처리, 구조화 저장**이 없음
- 실무에서는 최소한 JSON → line-delimited JSON (streaming), 혹은 sqlite, levelDB 등 고려

✅ 개선 제안:

- **파일 I/O를 비동기 Promise 기반으로 분리**
- 파일 포맷은 `.json` 보다는 `.jsonl` 또는 `.db` (구조화된 접근 허용)

---

## ✍️ 추천 구조 개선 예시

```
graphql
복사편집
/vector-db/
├── main.js
├── cli/
│   ├── input.js            # 사용자 입력 담당
│   └── handler.js          # 명령어에 따라 처리 (Command Dispatcher)
├── db/
│   ├── vdb.js              # in-memory DB 관리
│   ├── storage.js          # 저장/로드 전담
│   └── schema.js           # 데이터 구조 정의
├── embedding/
│   └── model.js            # transformers.js 또는 word2vec 로딩 및 벡터화
├── utils/
│   ├── distance.js         # 유사도/거리 계산
│   └── math.js             # meanPooling 등 수치 연산
├── config/
│   └── commands.js         # 명령 정의
└── storage/
    └── vectors.jsonl       # 저장되는 데이터

```

---

## 🔚 요약

| 항목 | 상태 | 개선 제안 |
| --- | --- | --- |
| 책임 분리 | ⚠️ 일부 애매 | utils 분해, storage 분리, handler 구조화 |
| 확장성 | 👍 양호 | enum/metadata 중심으로 강화 |
| 빠진 기능 | ❌ 있음 | 중복 검사, 예외 처리, graceful shutdown 등 |
| 스토리지 | ⚠️ 단순 | JSONL 혹은 구조화 파일 권장 |
| 명령 구조 | 👍 기반 좋음 | handler 분리로 testability 향상 |

<br>

**느낀점**

조건을 몇개 줬는데 생각보다 너무 자세히 잘 알려주는 것 같다.

</details>

---

### J225_임건혁 -퀘스트 5. 기본 퀴즈 생성기 아이디어
#### 선정이유 
아침에 멍하니 있는 시간에 기본 퀴즈 생성기를 사용하면 낭비하는 시간을 잘 활용할 수 있을것 같아서

#### 수행결과
